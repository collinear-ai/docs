---
title: Evaluate Synthetic Data
description: Assess the quality of generated synthetic data using Collinear AI's evaluation judges.
icon: file-search
---

## 🔍 Why Evaluate Synthetic Data?

**Quality evaluation** ensures your generated data meets standards for safety, reliability, and performance before use in production.

Key benefits:

- Validate synthetic data quality
- Identify potential issues early
- Compare generation model performance
- Establish quality benchmarks

## 🎥 Interactive Walkthrough

See synthetic data evaluation in action:

<div style={{ position: 'relative', paddingBottom: 'calc(56.67989417989418% + 41px)', height: 0, width: '100%' }}>
  <iframe
    src="https://demo.arcade.software/your-evaluation-demo-link"
    title="Synthetic Data Evaluation with Collinear AI"
    frameBorder="0"
    loading="lazy"
    allowFullScreen
    allow="clipboard-write"
    style={{ position: 'absolute', top: 0, left: 0, width: '100%', height: '100%', colorScheme: 'light' }}
  />
</div>

# Introduction

After generating synthetic data, evaluate it using Collinear AI's comprehensive assessment framework across three dimensions.


1. **Safety** – Detects harmful, biased, or privacy-violating content.
2. **Reliability** – Measures factual accuracy and hallucination risk.
3. **Performance** – Evaluates clarity, coherence, instruction following, and diversity.

---

## 🧑‍⚖️ Models Used for Judging

### 🔒 Safety

- **CollinearGuard** (Likert + rationale)
- **CollinearGuard Nano** (Binary / Binary with categories)
- **Llama Guard 3** (Binary with categories)
- **LLM As A Judge** (Custom)

### 📚 Reliability

- **Lynx 8B** – Binary + Rationale
- **Veritas Nano** – Binary
- **Veritas** – Binary + Rationale
- **LLM As A Judge** – Custom logic

### 🧠 Performance

- **CollinearFlex** – Likert
- **Diversity** – Numeric
- **Quality of Reasoning** – Likert
- **Instruction Following** – Likert
- **Coherence** – Internal metric

---

## 🚀 Getting Started

To evaluate synthetic data:

1. Upload or select generated dataset
2. Choose evaluation criteria
3. Select appropriate judges
4. Run evaluation
5. Review results


## 📊 Understanding Results

### Safety Evaluation Output Example
```json
{
  "rationale": "The response maintains safety by avoiding advice...",
  "score": 5
}