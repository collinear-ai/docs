---
title: Evaluate Synthetic Data
description: Assess the quality of generated synthetic data using Collinear AI's evaluation judges.
icon: file-search
---

## ğŸ” Why Evaluate Synthetic Data?

**Quality evaluation** ensures your generated data meets standards for safety, reliability, and performance before use in production.

Key benefits:

- Validate synthetic data quality
- Identify potential issues early
- Compare generation model performance
- Establish quality benchmarks

## ğŸ¥ Interactive Walkthrough

See synthetic data evaluation in action:

<div style={{ position: 'relative', paddingBottom: 'calc(56.67989417989418% + 41px)', height: 0, width: '100%' }}>
  <iframe
    src="https://demo.arcade.software/your-evaluation-demo-link"
    title="Synthetic Data Evaluation with Collinear AI"
    frameBorder="0"
    loading="lazy"
    allowFullScreen
    allow="clipboard-write"
    style={{ position: 'absolute', top: 0, left: 0, width: '100%', height: '100%', colorScheme: 'light' }}
  />
</div>

# Introduction

After generating synthetic data, evaluate it using Collinear AI's comprehensive assessment framework across three dimensions.


1. **Safety** â€“ Detects harmful, biased, or privacy-violating content.
2. **Reliability** â€“ Measures factual accuracy and hallucination risk.
3. **Performance** â€“ Evaluates clarity, coherence, instruction following, and diversity.

---

## ğŸ§‘â€âš–ï¸ Models Used for Judging

### ğŸ”’ Safety

- **CollinearGuard** (Likert + rationale)
- **CollinearGuard Nano** (Binary / Binary with categories)
- **Llama Guard 3** (Binary with categories)
- **LLM As A Judge** (Custom)

### ğŸ“š Reliability

- **Lynx 8B** â€“ Binary + Rationale
- **Veritas Nano** â€“ Binary
- **Veritas** â€“ Binary + Rationale
- **LLM As A Judge** â€“ Custom logic

### ğŸ§  Performance

- **CollinearFlex** â€“ Likert
- **Diversity** â€“ Numeric
- **Quality of Reasoning** â€“ Likert
- **Instruction Following** â€“ Likert
- **Coherence** â€“ Internal metric

---

## ğŸš€ Getting Started

To evaluate synthetic data:

1. Upload or select generated dataset
2. Choose evaluation criteria
3. Select appropriate judges
4. Run evaluation
5. Review results


## ğŸ“Š Understanding Results

### Safety Evaluation Output Example
```json
{
  "rationale": "The response maintains safety by avoiding advice...",
  "score": 5
}