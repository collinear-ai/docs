---
title: Curated Data
description: The Curated Data Dashboard is a sophisticated tool designed for managing and evaluating conversational models within an organizational framework. This dashboard serves as a centralized platform where various parameters and metrics related to the performance of models can be assessed, curated, and monitored. In this documentation, we will explore the core functionalities and components of the Curated Data Dashboard, detailing their usage and significance in maintaining and enhancing conversational AI systems.
---

<img
    style={{borderRadius: '0.5rem'}}
    src='/images/curated_data_dashboard.png'
/>

## Key Features of the Curated Data

### Evaluation Metrics Display
The dashboard header features several circular progress charts that display evaluation metrics for the models being tested. Each chart represents different aspects of model performance, including:
- LLM judge outputs
- Human annotations

These metrics provide a quick visual assessment of the model's current operational status and its alignment with expected standards.

### Query Console
The Query Console, located below the metric charts, enables users to perform specific searches and filter dashboard data. Users can enter queries related to conversational logs or data entries, making it easier to manage and access relevant information. This console is particularly valuable when navigating through large volumes of data and identifying specific entries for detailed review or analysis. For more information about the query language, please refer to our [query language documentation](/flows/query_language).

### Interactive Buttons
The dashboard provides a set of interactive buttons for performing various operations:

<Card title="Run Judgements">
Initiates the evaluation process where selected rows are assessed by LLM judges. This helps in evaluating the model's decision-making capabilities and response appropriateness.
</Card>

<Card title="Create Dataset">
Enables users to compile selected rows into a structured dataset. These datasets can be used for further analysis, training new models, or enhancing existing ones with real interaction data.
</Card>

<Card title="Create Judge">
Allows users to [construct a custom judge](/flows/create_custom_judge) setup based on human annotations. This feature helps ensure that evaluations align with specific organizational standards and objectives.
</Card>

### Data Table
The Data Table is the central component of the dashboard. It presents annotations in a structured format, providing a comprehensive overview of model-user interactions.

The table includes the following key columns:

<ResponseField name="ID" type="string">
A unique identifier for each entry in the table.
</ResponseField>

<ResponseField name="Conversation Prefix" type="string">
The initial prompt or query that triggers the model's response.
</ResponseField>

<ResponseField name="Response" type="string">
The generated output from the model in response to the conversation prefix.
</ResponseField>

<ResponseField name="Judge Feedback" type="string">
The evaluation feedback provided by the LLM judge.
</ResponseField>

<ResponseField name="Human Feedback" type="string">
The annotations provided by human evaluators, when available.
</ResponseField>