---
title: "Reliability Monitor"
description: "Track your AI system's consistency and accuracy with the Collinear AI Reliability Monitoring dashboard."
icon: "badge-check"
---

## Interactive Walkthrough

Explore the Reliability Monitoring dashboard in action:

<div style={{ position:"relative",paddingBottom:"calc(56.67989417989418% + 41px)",height:0,width:"100%" }}>
<iframe src="https://demo.arcade.software/hC5dtcZ9ZUGZysxSlgU7?embed&embed_mobile=tab&embed_desktop=inline&show_copy_link=true" title="Reliability Dashboard" frameBorder="0" loading="lazy" allowFullScreen allow="clipboard-write" style={{ position:"absolute",top:0,left:0,width:"100%",height:"100%",colorScheme:"light" }} />

</div>

---

## Key Metrics Overview

Monitor the most important indicators of AI reliability:

1. **Total Volume** – The number of queries processed.
2. **Reliability Index** – A measure of how consistently your AI performs without failures or inaccuracies.
3. **Factual Error Rate** – The percentage of responses that were factually incorrect.
4. **Contextual Error Rate** – The frequency at which responses are incorrect due to misinterpretation of context.

---

## Critical Summaries

Understand trends over time with visual insights:

- **Total Queries vs. Flagged Queries**
  View a time-series graph that compares the number of total queries with the number of flagged ones.
- **Flagged Categories**
  Categorization of flagged queries to identify common reliability issues.

---

## Hallucination Categories

Identify and classify the types of hallucinations detected in AI responses:

- **Logical** – Incorrect reasoning or fallacies.
- **Temporal** – Misstatements about time, dates, or sequencing.
- **Entity** – Inaccuracies about named entities (people, places, organizations).
- **Contextual** – Misunderstandings within conversational context.
- **Other** – Unclassified or ambiguous errors.

---

## Live Data

Access detailed evaluation records in real time:

| Field                   | Description                                            |
| ----------------------- | ------------------------------------------------------ |
| **ID**                  | Unique identifier for the conversation or query        |
| **Conversation Prefix** | Initial input or prompt given to the assistant         |
| **Model Response**      | The generated response from the Model                  |
| **Judge Output**        | Evaluation or score given by the system or human judge |
| **Feedback**            | Reviewer feedback                                      |
| **Categories**          | Labeled types of hallucination or issues               |

---