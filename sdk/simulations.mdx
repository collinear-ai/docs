---
title: Run Trait Basis Simulations
description: Configure trait basis payloads and batching when generating conversations with the Collinear Python SDK.
---

## Define the trait basis

A `SteerConfigInput` (used by the SDK today) describes the trait basis grid that drives sampling. Treat it as the source of truth for personas and intents. Keep all trait intensities between **0** and **2**.

```python
from collinear.schemas.steer import SteerConfigInput

trait_basis: SteerConfigInput = {
    "ages": ["young_adult", "middle_aged", "senior"],
    "genders": ["man", "woman"],
    "occupations": ["teacher", "software_engineer", "nurse"],
    "intents": [
        "billing_dispute",
        "cancel_service",
        "device_troubleshooting",
    ],
    "traits": {
        "confusion": [0, 2],
        "impatience": [0, 2],
    },
}
```

## Controlling Sample Volume

`Client.simulate` exposes levers for scale and pacing:

- `k`: number of trait basis combinations to draw; omit it to exhaust the full Cartesian product.
- `num_exchanges`: user/assistant pairs per conversation. Each exchange adds one user line and one assistant line.
- `batch_delay`: seconds to sleep between samples to avoid rate limits.
- `mix_traits`: set `True` to mix two traits per persona (requires at least two traits defined by the Trait Basis API).
- `steer_temperature` and `steer_max_tokens`: forwarded to the Trait Basis service when generating user turns.

```python
simulations = client.simulate(
    steer_config=trait_basis,
    k=5,
    num_exchanges=4,
    batch_delay=0.5,
    mix_traits=True,
    steer_temperature=0.6,
    steer_max_tokens=200,
)
```

Each `SimulationResult` contains the conversation prefix (`conv_prefix`), the assistant's final response (`response`), and the resolved trait basis attributes (`steer` in the SDK today).

## Custom Prompts and Tone

Override system prompts by editing the `SimulationRunner` attached to the client. Before calling `simulate`, set the templates you want to use:

```python
runner = client.simulation_runner
runner.USER_PROMPT_TEMPLATE = "You are a {age} traveler..."
runner.ASSISTANT_PROMPT_TEMPLATE = "You are a concierge..."
```

If you leave templates unset, the runner falls back to the SDK defaults defined in `SimulationRunner.ASSISTANT_PROMPT_TEMPLATE` and its generated user instructions.

## Logging and Progress

- Set `progress=False` on `simulate` to disable the tqdm progress bar (useful in headless environments).
- The runner logs each generated turn via the `collinear` logger. Configure logging in your script (`logging.basicConfig(level=logging.INFO)`) to see persona details and turn content.

## Saving Outputs

Convert results into JSONL for downstream tooling:

```python
from pathlib import Path
import json

out_path = Path("data/simulations.jsonl")
out_path.parent.mkdir(exist_ok=True)

with out_path.open("w", encoding="utf-8") as f:
    for sim in simulations:
        f.write(json.dumps(
            {
                "persona": sim.steer.model_dump() if sim.steer else None,
                "conversation": sim.conv_prefix,
                "assistant_response": sim.response,
            },
            ensure_ascii=False,
        ) + "\n")
```

Pair this with the recipes in the dedicated page to plug simulations into evaluation pipelines.
